\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {3}Policy Gradients}{1}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \color  {darkblue}The graph on the left displays the learning curves for the small batch runs, and the right displays those of the large batch runs.}}{1}{figure.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Neural Network Baseline}{3}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \color  {darkblue} The graph on the left depicts the learning curve for the baseline loss; the one on the right displays learning curve for the average returns (between using a baseline and not using a baseline). }}{3}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \color  {darkblue} The graph on the left displays the baseline loss curves of the extra experiments, and the right one displays their average return curves.}}{3}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Generalized Advantage Estimation}{5}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Hyperparameter Tuning}{6}{section.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \color  {darkblue} The graph on the left displays the learning curves with the default setting, and the one on the right displays the learning curves with my set of hyperparameters. \textbf  {We see that my hyperparameter tuning improved the convergence time from around 300,000 environment steps to around around 175,000 environment steps.}}}{6}{figure.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}(Extra Credit) Humanoid}{7}{section.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \color  {darkblue} We can see that the policy achieves an average return of far above 600 (i.e. around 900) by the end of training.}}{7}{figure.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Analysis}{8}{section.8}\protected@file@percent }
\newlabel{sec:analysis}{{8}{8}{Analysis}{section.8}{}}
\newlabel{sec:analysis@cref}{{[section][8][]8}{[1][8][]8}}
\newlabel{sec:analysis1}{{8.1}{8}{Analysis}{subsection.8.1}{}}
\newlabel{sec:analysis1@cref}{{[question][1][8]8.1}{[1][8][]8}}
\newlabel{exact_gradient}{{1b}{9}{Analysis}{Item.6}{}}
\newlabel{exact_gradient@cref}{{[enumii][2][1]1b}{[1][9][]9}}
\newlabel{sec:analysis2}{{8.2}{10}{Analysis}{subsection.8.2}{}}
\newlabel{sec:analysis2@cref}{{[question][2][8]8.2}{[1][10][]10}}
\newlabel{sec:analysis3}{{8.3}{11}{Analysis}{subsection.8.3}{}}
\newlabel{sec:analysis3@cref}{{[question][3][8]8.3}{[1][11][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \color  {darkblue} We see that the return-to-go policy controls the variance better.}}{12}{figure.6}\protected@file@percent }
\newlabel{sec:analysis4}{{8.4}{12}{Analysis}{subsection.8.4}{}}
\newlabel{sec:analysis4@cref}{{[question][4][8]8.4}{[1][12][]12}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Survey}{14}{section.9}\protected@file@percent }
\newlabel{sec:survey}{{9}{14}{Survey}{section.9}{}}
\newlabel{sec:survey@cref}{{[section][9][]9}{[1][14][]14}}
\gdef \@abspage@last{14}
